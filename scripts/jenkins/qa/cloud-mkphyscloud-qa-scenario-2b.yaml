- job:
    name: cloud-mkphyscloud-qa-scenario-2b
    node: cloud-mkphyscloud-gate-qa
    description: |
      <b>This job is managed by JJB! Changes must be done in
      <a href='https://github.com/SUSE-Cloud/automation/tree/master/scripts/jenkins/qa/'>git</a>
      </b>

      This job will redeploy the scenario-2b:
        - total 7 nodes
        - database: default, postgresql
        - pacemaker: 1 cluster with 3 controllers
        - nova: ssl, libvirt migration enabled, shared storage, kvm kernel samepage merging, 2 kvm and 2 ESXi compute nodes
        - cinder: vmware
        - neutron: vmware (but currently ovs as NSX plugin is kind of out of order)
        - eveyrthing with SSL.

      Warning: It will wipe all machines!

    wrappers:
      - mkphyscloud-qa-common-wrappers
    publishers:
      - mkphyscloud-qa-common-publishers

    logrotate:
      numToKeep: 7
      daysToKeep: -1

    parameters:
      - string:
          name: hw_number
          default: "2"
          description: Mandatory, name of the QA cloud server as integer

      - string:
          name: tempest
          default: smoke
          description: Optional, specify what tempest test(s) to run, e.g. smoke, smoke|full or smoke|defcore

      - string:
          name: cct
          default: features:base
          description: Optional, specify cct tests to run

      - string:
          name: ssl_type
          default: no-ssl
          description: "Mandatory, set the SSL configuration for the cloud, available options: no-ssl, ssl-insecure, ssl"

      - string:
          name: cloud_version
          default: "7"
          description: Mandatory, version of the cloud to be installed as integer

      - string:
          name: scenario_url
          default: https://raw.githubusercontent.com/SUSE-Cloud/automation/master/scripts/scenarios/cloud$cloud_version/qa/$ssl_type/qa-scenario-2b.yaml
          description: Location of scenario yaml file

      # Parameters for qa_crowbarsetup.sh
      - string:
          name: cloudsource
          default: develcloud$cloud_version
      - string:
          name: TESTHEAD
          default: "1"
          description: if non-empty, test latest version from Devel:Cloud Stagin
      - string:
          name: hacloud
          default: "1"
          description: By default we do not want HA configured and installed
      - string:
          name: clusterconfig
          default: services=3
          description: HA configuration for clusters. Make sense only if hacloud=1
      - string:
          name: nodenumber
          default: "6"
          description: Number of nodes to use; is scenario specific
      - string:
          name: want_ipmi
          default: "true"
      - string:
          name: runner_url
          default: https://raw.githubusercontent.com/SUSE-Cloud/automation/master/scripts/qa_crowbarsetup.sh
          description: The runner must be qa_crowbarsetup.sh file
      - string:
          name: commands
          default: prepareinstallcrowbar bootstrapcrowbar installcrowbar allocate setup_aliases waitcloud
          description: All the steps that needs to be completed to have cloud installed
      - text:
          name: UPDATEREPOS
          default:
          description: Update repositories (one URL per line)
      - bool:
          name: UPDATEBEFOREINSTALL
          default: false
          description: add update repos before crowbar install

    builders:
      - shell: |
          #!/bin/bash
          admin=crowbar$hw_number
          cloud=qa$hw_number
          vcenter_user="Administrator@vsphere.qa.suse.de"
          vcenter_password=`cat /home/jenkins/passwords/Administrator\@vsphere.qa.suse.de`

          if [ ! -z "$UPDATEREPOS" ] ; then
            # testing update only makes sense with GMx and without TESTHEAD
            unset TESTHEAD
            export UPDATEREPOS=${UPDATEREPOS//$'\n'/+}
          fi

          export artifacts_dir=$WORKSPACE/.artifacts
          rm -rf $artifacts_dir
          mkdir -p $artifacts_dir
          touch $artifacts_dir/.ignore

          freshadminvm $admin
          sleep 100 # time for the admin VM to boot

          # wipe out shared NFS that should be used by this deployment
          ssh root@localhost "wipe_nfs_shares qa$hw_number"

          # rest of code runs on admin node:
          env | grep -e networking -e libvirt -e cloud > mkcloud.config
          scp mkcloud.config root@$admin:
          ret=0

          ssh root@$admin "
          export cloud=$cloud ;
          export hw_number=$hw_number ;
          export UPDATEREPOS=$UPDATEREPOS ;
          export UPDATEBEFOREINSTALL=$UPDATEBEFOREINSTALL ;
          export TESTHEAD=$TESTHEAD ;
          export cloudsource=$cloudsource ;
          export nodenumber=$nodenumber ;
          export hacloud=$hacloud ;
          export clusterconfig=$clusterconfig ;
          export runner_url=$runner_url ;
          export scenario_url=$scenario_url ;
          export want_node_aliases=controller=3,computekvm=2,computevmw=1 ;
          export want_node_roles=controller=3,compute=4 ;
          export scenario=\"scenario.yml\" ;
          export commands=\"$commands\" "'

          wget --no-check-certificate -Oqa_crowbarsetup.sh "$runner_url"
          wget --no-check-certificate -Oscenario.yml "$scenario_url"

          sed -i -e "s,##shared_nfs_for_database##,10.162.66.1:/var/$cloud/ha-database," scenario.yml
          sed -i -e "s,##shared_nfs_for_rabbitmq##,10.162.66.1:/var/$cloud/ha-rabbitmq," scenario.yml

          [ $UPDATEBEFOREINSTALL == "true" ] && export updatesteps="addupdaterepo runupdate"

          timeout --signal=ALRM 240m bash -x -c ". qa_crowbarsetup.sh ; onadmin_runlist $commands"
          ' || ret=$?

          echo "mkphyscloud ret=$ret (before scenario)"

          if [ "$ret" = "0" ]; then
            # ----- Prepare the SBD setup:
            cat > /tmp/sbd_prepare_$admin <<EOSCRIPT
              # preparation of iSCSI
              zypper --gpg-auto-import-keys -p http://download.opensuse.org/repositories/devel:/languages:/python/SLE_12_SP2/ --non-interactive install python-sh
              wget --no-check-certificate https://raw.githubusercontent.com/SUSE-Cloud/automation/master/scripts/iscsictl.py
              chmod +x iscsictl.py
              ./iscsictl.py --service target --host \$(hostname) --no-key
              ./iscsictl.py --service initiator --target_host \$(hostname) --host controller1 --no-key
              ./iscsictl.py --service initiator --target_host \$(hostname) --host controller2 --no-key
              ./iscsictl.py --service initiator --target_host \$(hostname) --host controller3 --no-key
              # preparation of SBD
              SBD_DEV=\$(ssh controller1 echo '/dev/disk/by-id/scsi-\$(lsscsi -i | grep LIO | tr -s " " |cut -d " " -f7)')
              ssh controller1 "zypper --non-interactive install sbd; sbd -d \$SBD_DEV create"
              ssh controller2 "zypper --non-interactive install sbd"
              ssh controller3 "zypper --non-interactive install sbd"
              # watchdog configuration
              ssh controller1 modprobe softdog; echo softdog > /etc/modules-load.d/watchdog.conf
              ssh controller2 modprobe softdog; echo softdog > /etc/modules-load.d/watchdog.conf
              ssh controller3 modprobe softdog; echo softdog > /etc/modules-load.d/watchdog.conf
              # take scenario yaml file and replace placeholders with right things:
              sed -i "s|@@sbd_device@@|\${SBD_DEV}|g" scenario.yml
              sed -i "s|@@vcenter_user@@|\${vcenter_user}|g" scenario.yml
              sed -i "s|@@vcenter_password@@|\${vcenter_password}|g" scenario.yml
              # ----- End of SBD
          EOSCRIPT
            chmod +x /tmp/sbd_prepare_$admin
            scp /tmp/sbd_prepare_$admin root@$admin:sbd_prepare
            ssh root@$admin './sbd_prepare
            ' || ret=$?
          fi
          if [ "$ret" = "0" ]; then
            ssh root@$admin "
            export cloud=$cloud ;
            export TESTHEAD=$TESTHEAD ;
            export cloudsource=$cloudsource ;
            export nodenumber=$nodenumber ;
            export hacloud=$hacloud ;
            export clusterconfig=$clusterconfig ;
            export want_ceph=1 ;
            export cephvolumenumber=2;
            export scenario=scenario.yml "'

            timeout --signal=ALRM 240m bash -x -c ". qa_crowbarsetup.sh ; onadmin_runlist batch;"
            ' || ret=$?


            if [ $ret != 0 ] ; then
              ssh root@$admin '
              set -x
              for node in $(crowbar machines list | grep ^d) ; do
                (
                echo "Collecting supportconfig from $node"
                timeout 400 ssh $node supportconfig | wc
                timeout 300 scp $node:/var/log/\*tbz /var/log/
                )&
              done
              timeout 500 supportconfig | wc &
              wait
              '

              scp root@$admin:/var/log/*tbz $artifacts_dir/
            fi >&2
            echo "mkphyscloud ret=$ret"
          fi
          exit $ret

      - trigger-builds:
          - project: cloud-mkphyscloud-qa-tests-trigger
            condition: SUCCESS
            block: true
            predefined-parameters: |
              hw_number=$hw_number
              tempest=$tempest
              cct_tests=$cct
              scenario_name=2b
              scenario_job_name=$JOB_NAME
              scenario_build_number=$BUILD_NUMBER
